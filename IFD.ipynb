{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Convert the input image to an ELA (Error Level Analysis) applied image\n",
    "def convert_to_ela_image(path, quality):\n",
    "\n",
    "    original_image = Image.open(path).convert('RGB')\n",
    "\n",
    "    # Save the input image again with the desired quality\n",
    "    resaved_file_name = 'resaved_image.jpg'  # default name for the resaved image\n",
    "    original_image.save(resaved_file_name, 'JPEG', quality=quality)\n",
    "    resaved_image = Image.open(resaved_file_name)\n",
    "\n",
    "    # Pixel difference between the original image and the resaved image\n",
    "    ela_image = ImageChops.difference(original_image, resaved_image)\n",
    "\n",
    "    # Scale factors are calculated from the extremes of the pixels\n",
    "    extrema = ela_image.getextrema()\n",
    "    max_difference = max([pix[1] for pix in extrema])\n",
    "    if max_difference == 0:\n",
    "        max_difference = 1\n",
    "    scale = 350.0 / max_difference\n",
    "\n",
    "    # Enhance the ELA image to brighten the pixels\n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "\n",
    "    ela_image.save(\"ela_image.png\")\n",
    "    return ela_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image_path):\n",
    "    image_size = (128, 128)\n",
    "    #normalizing the array values obtained from input image\n",
    "    return np.array(convert_to_ela_image(image_path, 90).resize(image_size)).flatten() / 255.0         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # ELA converted images\n",
    "Y = [] # 0 for fake, 1 for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding authentic images\n",
    "\n",
    "path = './data/authentic'       #folder path of the authentic images in the dataset\n",
    "for filename in tqdm(os.listdir(path),desc=\"Processing Images : \"):\n",
    "    if filename.endswith('jpg') or filename.endswith('png'):\n",
    "        full_path = os.path.join(path, filename)\n",
    "        X.append(prepare_image(full_path))        \n",
    "        Y.append(1)     # label for authentic images \n",
    "        \n",
    "print(f'Total images: {len(X)}\\nTotal labels: {len(Y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding forged images\n",
    "\n",
    "path = './data/forged'       #folder path of the forged images in the dataset\n",
    "for filename in tqdm(os.listdir(path),desc=\"Processing Images : \"):\n",
    "    if filename.endswith('jpg') or filename.endswith('png'):\n",
    "        full_path = os.path.join(path, filename)\n",
    "        X.append(prepare_image(full_path))        \n",
    "        Y.append(0)     # label for forged images \n",
    "        \n",
    "print(f'Total images: {len(X)}\\nTotal labels: {len(Y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X = X.reshape(-1, 128, 128, 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning dataset for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training : Validation : Testing \n",
    "X_temp, X_test, Y_temp, Y_test = train_test_split(X, Y, test_size = 0.05, random_state=5)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size = 0.2, random_state=5)\n",
    "X = X.reshape(-1,1,1,1)\n",
    "\n",
    "print(f'Training images: {len(X_train)} , Training labels: {len(Y_train)}')\n",
    "print(f'Validation images: {len(X_val)} , Validation labels: {len(Y_val)}')\n",
    "print(f'Test images: {len(X_test)} , Test labels: {len(Y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(128, 128, 3)))  # Definisce l'input come primo strato\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='valid', activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='valid', activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='valid', activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "init_lr = 1e-4   #learning rate for the optimizer\n",
    "optimizer = Adam(learning_rate=init_lr, weight_decay=init_lr/epochs)\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early Stopping\n",
    "early_stopping = EarlyStopping(monitor = 'val_accuracy',\n",
    "                               min_delta = 0,\n",
    "                               patience = 10,\n",
    "                               verbose = 0,\n",
    "                               mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist = model.fit(X_train,\n",
    "                 Y_train,\n",
    "                 batch_size = batch_size,\n",
    "                 epochs = epochs,\n",
    "                 validation_data = (X_val, Y_val),\n",
    "                 callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model as a h5 file\n",
    "model.save('.h5') \n",
    "\n",
    "# get the dictionary containing each metric and the loss for each epoch\n",
    "history_dict = hist.history\n",
    "\n",
    "# save it as a json file\n",
    "json.dump(history_dict, open('', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, color=\"#E74C3C\", label='Train Loss', marker='o')\n",
    "    plt.plot(val_losses, color=\"#641E15\", label='Validation Loss', marker='h')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, color=\"#E74C3C\", label='Train Accuracy', marker='o')\n",
    "    plt.plot(val_accuracies, color=\"#641E15\", label='Validation Accuracy', marker='h')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the training and validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = history_dict['loss']\n",
    "val_losses = history_dict['val_loss']\n",
    "train_accuracies = history_dict['accuracy']\n",
    "val_accuracies = history_dict['val_accuracy']\n",
    "\n",
    "plot_loss_accuracy(train_losses, val_losses, train_accuracies, val_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(conf_matrix, class_names):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax, xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_val)  # Predict the values from the validation dataset\n",
    "Y_pred_classes = np.round(Y_pred)  # Round off the sigmoid value\n",
    "\n",
    "Y_true = Y_val\n",
    "class_names = ['Forged', 'Authentic']\n",
    "conf_matrix = confusion_matrix(Y_true, Y_pred_classes)\n",
    "\n",
    "print_confusion_matrix(conf_matrix, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_true, Y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Forged', 'Authentic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing accuracy\n",
    "correct_test = 0 #correctly predicted test images\n",
    "total_test = 0   #total test images\n",
    "\n",
    "for index,image in enumerate(tqdm(X_test,desc=\"Processing Images : \")):\n",
    "    image = image.reshape(-1, 128, 128, 3)\n",
    "    y_pred = model.predict(image)\n",
    "    y_pred_class = np.round(y_pred)\n",
    "    total_test += 1\n",
    "    if y_pred_class == Y_test[index]: #if prediction is correct\n",
    "        correct_test += 1\n",
    "    \n",
    "print(f'Total test images: {total_test}\\nCorrectly predicted images: {correct_test}\\nAccuracy: {correct_test / total_test * 100.0} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(fname):\n",
    "    # return ela_image as a numpy array\n",
    "    image_size = (128, 128)\n",
    "    return (\n",
    "        np.array(convert_to_ela_image(fname, 90).resize(image_size)).flatten()\n",
    "        / 255.0\n",
    "    )  \n",
    "\n",
    "def predict_result(fname):\n",
    "    model = load_model(\"trained_model.h5\")  # load the trained model\n",
    "    class_names = [\"Forged\", \"Authentic\"]  # classification outputs\n",
    "    test_image = prepare_image(fname)\n",
    "    test_image = test_image.reshape(-1, 128, 128, 3)\n",
    "\n",
    "    y_pred = model.predict(test_image)\n",
    "    y_pred_class = round(y_pred[0][0])\n",
    "\n",
    "    prediction = class_names[y_pred_class]\n",
    "    if y_pred <= 0.5:\n",
    "        confidence = f\"{(1-(y_pred[0][0])) * 100:0.2f}\"\n",
    "    else:\n",
    "        confidence = f\"{(y_pred[0][0]) * 100:0.2f}\"\n",
    "    return (prediction, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = './data/test/forged/splicing.jpg'    # test image path\n",
    "test_image = prepare_image(test_image_path)\n",
    "test_image = test_image.reshape(-1, 128, 128, 3)\n",
    "\n",
    "y_pred = model.predict(test_image)\n",
    "y_pred_class = round(y_pred[0][0])\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,5)) \n",
    "\n",
    "#display original image\n",
    "original_image = plt.imread(test_image_path) \n",
    "ax[0].axis('off')\n",
    "ax[0].imshow(original_image)\n",
    "ax[0].set_title('Original Image')\n",
    "\n",
    "#display ELA applied image\n",
    "ax[1].axis('off')\n",
    "ax[1].imshow(convert_to_ela_image(test_image_path,90)) \n",
    "ax[1].set_title('ELA Image')\n",
    "\n",
    "print(f'Prediction: {class_names[y_pred_class]}')\n",
    "if y_pred<=0.5:\n",
    "    print(f'Confidence:  {(1-(y_pred[0][0])) * 100:0.2f}%')\n",
    "else:\n",
    "    print(f'Confidence: {(y_pred[0][0]) * 100:0.2f}%')\n",
    "print('--------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = './data/test/authentic/img2.jpg'    # test image path\n",
    "test_image = prepare_image(test_image_path)\n",
    "test_image = test_image.reshape(-1, 128, 128, 3)\n",
    "\n",
    "y_pred = model.predict(test_image)\n",
    "y_pred_class = round(y_pred[0][0])\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,5)) \n",
    "\n",
    "#display original image\n",
    "original_image = plt.imread(test_image_path) \n",
    "ax[0].axis('off')\n",
    "ax[0].imshow(original_image)\n",
    "ax[0].set_title('Original Image')\n",
    "\n",
    "#display ELA applied image\n",
    "ax[1].axis('off')\n",
    "ax[1].imshow(convert_to_ela_image(test_image_path,90)) \n",
    "ax[1].set_title('ELA Image')\n",
    "\n",
    "print(f'Prediction: {class_names[y_pred_class]}')\n",
    "if y_pred<=0.5:\n",
    "    print(f'Confidence:  {(1-(y_pred[0][0])) * 100:0.2f}%')\n",
    "else:\n",
    "    print(f'Confidence: {(y_pred[0][0]) * 100:0.2f}%')\n",
    "print('--------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder_path = './data/test/dataset/'\n",
    "authentic, forged, total = 0, 0, 0\n",
    "y_true, y_pred_custom = [], []\n",
    "\n",
    "for filename in tqdm(os.listdir(test_folder_path), desc=\"Processing Images : \"):\n",
    "    if filename.endswith('jpg') or filename.endswith('png'):\n",
    "        test_image_path = os.path.join(test_folder_path, filename)\n",
    "        test_image = prepare_image(test_image_path)  \n",
    "        \n",
    "        if test_image is not None:\n",
    "            test_image = test_image.reshape(-1, 128, 128, 3)\n",
    "            y_pred = model.predict(test_image)\n",
    "            y_pred_class = np.round(y_pred)\n",
    "            \n",
    "            y_true.append(0 if 'forged' in filename.lower() else 1)\n",
    "            y_pred_custom.append(y_pred_class)\n",
    "\n",
    "            total += 1\n",
    "            if y_pred_class == 0:\n",
    "                forged += 1\n",
    "            else:\n",
    "                authentic += 1\n",
    "\n",
    "print(f'Total images: {total}\\nAuthentic Images: {authentic}\\nForged Images: {forged}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with well known models 'GoogleNet', 'SqueezeNet' and 'AlexNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i modelli pre-addestrati\n",
    "googlenet = models.googlenet(pretrained=True)\n",
    "squeezenet = models.squeezenet1_0(pretrained=True)\n",
    "alexnet = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, device, epochs=15):\n",
    "    model.to(device)  \n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.float()) \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "\n",
    "    return train_losses, train_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(X_train, Y_train, transform=transform)\n",
    "val_dataset = CustomDataset(X_val, Y_val, transform=transform)\n",
    "test_dataset = CustomDataset(X_test, Y_test, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Verify the data\n",
    "for inputs, labels in train_loader:\n",
    "    print(inputs.shape, labels.shape)  \n",
    "    break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#train_losses_googlenet, train_accuracies_googlenet = train_model(googlenet, train_loader, device=dev, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_losses_squeezenet, train_accuracies_squeezenet = train_model(squeezenet, train_loader, device=dev, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_alexnet, train_accuracies_alexnet = train_model(alexnet, train_loader, device=dev, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models finetuned and them histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(googlenet.state_dict(), 'googlenet_finetuned.pt')\n",
    "torch.save(squeezenet.state_dict(), 'squeezenet_finetuned.pt')\n",
    "torch.save(alexnet.state_dict(), 'alexnet_finetuned.pt')\n",
    "\n",
    "history_googlenet = {\n",
    "    'train_losses': train_losses_googlenet,\n",
    "    'train_accuracies': train_accuracies_googlenet\n",
    "}\n",
    "\n",
    "history_squeezenet = {\n",
    "    'train_losses': train_losses_squeezenet,\n",
    "    'train_accuracies': train_accuracies_squeezenet\n",
    "}\n",
    "\n",
    "history_alexnet = {\n",
    "    'train_losses': train_losses_alexnet,\n",
    "    'train_accuracies': train_accuracies_alexnet\n",
    "}\n",
    "\n",
    "with open('googlenet_history.json', 'w') as f:\n",
    "    json.dump(history_googlenet, f)\n",
    "\n",
    "with open('squeezenet_history.json', 'w') as f:\n",
    "    json.dump(history_squeezenet, f)\n",
    "\n",
    "with open('alexnet_history.json', 'w') as f:\n",
    "    json.dump(history_alexnet, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot train curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot delle curve di loss e accuracy\n",
    "def plot_loss_accuracy(train_losses, train_accuracies, model_name):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, color=\"#641E15\", label='Validation Accuracy', marker='h')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title(f'{model_name} Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, color=\"#E74C3C\", label='Train Accuracy', marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(f'{model_name} Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(train_losses_googlenet, train_accuracies_googlenet, \"GoogLeNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(train_losses_squeezenet, train_accuracies_squeezenet, \"SqueezeNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(train_losses_alexnet, train_accuracies_alexnet, \"AlexNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "<h4>\n",
    "Due to time constraints, only a limited number of training epochs were permitted for the GoogLeNet and SqueezeNet models. <br>\n",
    "However, this is not a significant issue as both models are highly complex and require extensive training time. Furthermore, as evidenced by the learning curves, both models demonstrated excellent generalisation capabilities, indicating that even with limited training, they can already offer remarkable performance.\n",
    "</h4>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
